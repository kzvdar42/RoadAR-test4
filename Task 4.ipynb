{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for object detection is taken from [here](https://github.com/cfotache/pytorch_objectdetecttrack) and modified to work with the video instead of images.\n",
    "\n",
    "Before running this file, be sure that the `config/yolov3.weights` file is downloaded, otherwise run the `config/download_weights.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Darknet\n",
    "from utils import utils\n",
    "\n",
    "import os, sys, time, datetime, random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load true bounding boxes.\n",
    "with open('data/input_annotations.json') as in_file:\n",
    "    annotations = json.load(in_file)\n",
    "true_tracks = defaultdict(list)\n",
    "for annot in annotations['annotations']:\n",
    "    true_tracks[annot['image_id']].append(annot['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_path = 'config/yolov3.cfg'\n",
    "weights_path = 'config/yolov3.weights'\n",
    "class_path = 'config/coco.names'\n",
    "img_size = 416\n",
    "\n",
    "# Visualise the detection or not.\n",
    "visualize = True\n",
    "# Class confidence and non-max suppression threshholds for object detection.\n",
    "conf_thres=0.2\n",
    "nms_thres=0.4\n",
    "\n",
    "# Load model and weights.\n",
    "model = Darknet(config_path, img_size=img_size)\n",
    "model.load_weights(weights_path)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "classes = utils.load_classes(class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(img, img_size):\n",
    "    \"\"\"Detect the objects on the image.\n",
    "    \n",
    "    Scales input image to the needed size keeping the aspect ratio.\n",
    "    Merges classes that are close to the car (bus, train, truck).\n",
    "    Performes non-max suppression on resulting bboxes.\n",
    "    \"\"\"\n",
    "    ratio = min(img_size / img.shape[0], img_size / img.shape[1])\n",
    "    imw = round(img.shape[0] * ratio)\n",
    "    imh = round(img.shape[1] * ratio)\n",
    "    img = cv2.resize(img, (imh, imw))\n",
    "    img = cv2.copyMakeBorder(img,\n",
    "                             max(int((imh-imw)/2),0), # top\n",
    "                             max(int((imh-imw)/2),0), # bottom\n",
    "                             max(int((imw-imh)/2),0), # left\n",
    "                             max(int((imw-imh)/2),0), # right\n",
    "                             cv2.BORDER_CONSTANT, value=128)\n",
    "    img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    image_tensor = torch.Tensor(np.asarray(img)).float().cuda()\n",
    "    image_tensor = image_tensor.permute((2, 0, 1))\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    # run inference on the model and get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(image_tensor) # [1, 10647, 85]\n",
    "        for class_id in [10, 11, 12]: # 5 + class_id; 3 - motorbike; 5 - bus; 6 - train; 7 - truck\n",
    "            detections[:, :, 7] = torch.max(detections[:, :, 7], detections[:, :, class_id]) \n",
    "            detections[:, :, class_id] = 0\n",
    "        # num_of_classes = 7, because we need only first 7\n",
    "        detections = utils.non_max_suppression(detections, 7, conf_thres, nms_thres)\n",
    "    return detections[0]\n",
    "\n",
    "def scale_bboxes(from_shape, to_shape, bboxes):\n",
    "    \"\"\"Scale the bboxes coordinates.\n",
    "    \n",
    "    :param bboxes: bboxes in format (x1, y1, x2, y2, *data).\n",
    "    \"\"\"\n",
    "    pad_x = max(to_shape[0] - to_shape[1], 0) * (from_shape / max(to_shape))\n",
    "    pad_y = max(to_shape[1] - to_shape[0], 0) * (from_shape / max(to_shape))\n",
    "    unpad_h = from_shape - pad_y\n",
    "    unpad_w = from_shape - pad_x\n",
    "    # browse detections and draw bounding boxes\n",
    "    for i, (x1, y1, x2, y2, *_) in enumerate(bboxes):\n",
    "        box_h = ((y2 - y1) / unpad_h) * to_shape[0]\n",
    "        box_w = ((x2 - x1) / unpad_w) * to_shape[1]\n",
    "\n",
    "        x1 = ((x1 - pad_x // 2) / unpad_w) * to_shape[1]\n",
    "        y1 = ((y1 - pad_y // 2) / unpad_h) * to_shape[0]\n",
    "        bboxes[i][:4] = x1, y1, x1 + box_w, y1 + box_h\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input video.\n",
    "cap = cv2.VideoCapture('data/input.avi')\n",
    "# Output video.\n",
    "out = cv2.VideoWriter('data/out.avi', cv2.VideoWriter_fourcc(*'XVID'), 23.63, (1920, 1088))\n",
    "\n",
    "\n",
    "# Check if camera opened successfully.\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "pr_tracks = defaultdict(list)\n",
    "pr_confidence = defaultdict(list)\n",
    "frame_num = 1\n",
    "\n",
    "# Get the number of frames\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=frame_count, desc='Object Detection')\n",
    "# Read until video is completed.\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame.\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert to RGB and detect objects.\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detections = detect_image(rgb_frame, img_size).cpu().detach().numpy()\n",
    "    detections = scale_bboxes(img_size, frame.shape, detections)\n",
    "\n",
    "\n",
    "    for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "        # If detected car, add to the predicted tracks.\n",
    "        if classes[int(cls_pred)] == 'car':\n",
    "            pr_tracks[frame_num].append((x1.item(), y1.item(), (x2 - x1).item(), (y2 - y1).item()))\n",
    "            pr_confidence[frame_num].append(cls_conf)\n",
    "            if visualize:\n",
    "                # Visualise the predicted bbox and class.\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, classes[int(cls_pred)], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0))\n",
    "                \n",
    "                # Visualise the ground truth bboxes.\n",
    "                for x1, y1, w, h in true_tracks[frame_num]:\n",
    "                    x1, y1, w, h = int(x1), int(y1), int(w), int(h)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
    "    if visualize:\n",
    "        cv2.imshow('Frame', frame)\n",
    "    out.write(frame)\n",
    "    frame_num += 1\n",
    "    pbar.update(1)\n",
    "    # Press Q on keyboard to  exit.\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "pbar.close()\n",
    "# When everything done, release objects.\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the precision-recall curve and AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = utils.compute_precision_recall_curve(true_tracks, pr_tracks, pr_confidence, thresh=0.5)\n",
    "\n",
    "ap = utils.compute_ap(recall, precision)\n",
    "print(f'AP score: {ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(recall, precision)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
